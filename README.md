# WebScraper AI ğŸ•¸ï¸ğŸ¤–

An intelligent, modular, and LLM-integrated web scraping framework.

WebScraper AI enables structured data extraction from any website using either traditional scraping (Selenium with ChromeDriver) or advanced scraping (Bright Data Scraping Browser). Extracted HTML content is then processed using powerful LLMs such as OpenAI or local Ollama models.


# ğŸ“‚ Project Architecture
``` bash
webscraper_ai/
â”‚
â”œâ”€â”€ app/ ğŸ§                          # Application logic (use cases, LLM parsing)
â”‚   â””â”€â”€ use_cases/
â”‚       â””â”€â”€ parsing/
â”‚           â”œâ”€â”€ ollama_parser.py ğŸ¦™    # Ollama LLM parser
â”‚           â””â”€â”€ openai_parser.py ğŸ’¬   # OpenAI GPT parser
â”‚
â”œâ”€â”€ infrastructure/ ğŸŒ              # External systems and integrations
â”‚   â””â”€â”€ scraping/
â”‚       â”œâ”€â”€ brightdata_scraper.py ğŸ›¡ï¸   # CAPTCHA-resistant scraping
â”‚       â”œâ”€â”€ chrome_scraper.py ğŸ•¸ï¸      # Headless ChromeDriver scraper
â”‚       â””â”€â”€ utils.py ğŸ§¹               # HTML cleaner and text splitter
â”‚
â”œâ”€â”€ tests/ ğŸ§ª                      # Unit and integration tests
â”‚   â””â”€â”€ unit/
â”‚       â””â”€â”€ scraping/
â”‚           â””â”€â”€ test_utils.py âœ…     # Tests for HTML/text utilities
â”‚
â”œâ”€â”€ interfaces/ ğŸš€                 # Entry points (CLI, API)
â”‚   â””â”€â”€ cli/
â”‚       â””â”€â”€ main.py ğŸ§¾              # CLI script to trigger scraping/parsing
â”‚
â”œâ”€â”€ config/ âš™ï¸                    # Environment and settings
â”‚   â””â”€â”€ settings.py ğŸ› ï¸            # Loads model and scraper config from .env
â”œâ”€â”€ drivers/ ğŸ§°
â”‚   â””â”€â”€ chromedriver.exe ğŸ”§        # ChromeDriver binary for local scraping
â”œâ”€â”€ .env ğŸ”                        # Environment secrets (ignored by Git)
â”œâ”€â”€ requirements.txt ğŸ“¦            # Python dependencies
â”œâ”€â”€ Dockerfile ğŸ³                  # Deployment container configuration
â””â”€â”€ README.md ğŸ“–                   # Project documentation


```


---

## ğŸš€ Features

- ğŸ§  DOM parsing powered by OpenAI GPT or local Ollama LLMs
- ğŸ•·ï¸ Basic web scraping using ChromeDriver (headless)
- ğŸ›¡ï¸ CAPTCHA-resistant scraping via Bright Data Scraping Browser
- ğŸ§¹ HTML cleaner and content splitter utilities
- âœ… Fully testable with Pytest

---



## âš™ï¸ Setup

### 1. Clone the repo

```bash
git clone https://github.com/your-username/webscraper_ai.git
cd webscraper_ai
```

### Install dependencies
``` bash
pip install -r requirements.txt

```

### Create a .env file
``` bash
OPENAI_API_KEY=
SBR_WEBDRIVER=
OLLAMA_MODEL=llama3.1:latest
OPENAI_MODEL=gpt-4o
CHROMEDRIVER_PATH=drivers/chromedriver.exe

```

---

## ğŸ§© Dependencies

This project relies on the following Python libraries:

### ğŸ” Web Scraping
- `selenium` â€“ browser automation
- `beautifulsoup4`, `lxml`, `html5lib` â€“ HTML parsing engines
- `undetected-chromedriver` â€“ evades bot detection
- `python-dotenv` â€“ environment variable management

### ğŸ§  LLM & Parsing
- `openai` â€“ access to models
- `langchain`, `langchain-core`, `langchain-community` â€“ LLM orchestration framework
- `langchain-openai`, `langchain-ollama` â€“ LangChain integrations
- `ollama` â€“ local LLM runtime

### ğŸ–¥ï¸ Web UI (optional)
- `streamlit` â€“ interactive UI for local testing or visualization

### ğŸ§¹ HTML Post-Processing
- `html2text` â€“ converts HTML to plain text
- `tqdm` â€“ progress bars during long-running tasks
- `requests` â€“ simple HTTP requests

### âš™ï¸ Config & Utilities
- `pydantic` â€“ type-safe settings and data validation


